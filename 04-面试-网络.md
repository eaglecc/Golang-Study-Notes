# 网络

## 1. 浏览器输入 URL 的一个过程

1. 网络进程查找本地缓存，是否有页面资源缓存。

   1. 有缓存，返回资源给浏览器进程。
   2. 没有缓存，进入网络请求流程。

2. 查找 DNS 缓存。（查域名对应的IP）

   1. 有缓存，获取请求域名的 IP 地址。
   2. 没有缓存，向 DNS 发送请求，获取 IP 地址。

3. 根据 IP 和端口号，建立 TCP 连接。

   1. 如果请求协议是 HTTPS，需要建立 TLS 连接。
   2. 用一域名同时最多建立 6 个 TCP 连接，看你需要等待。

4. 通过网络层IP协议 进一步添加IP头（源地址IP、目的IP等）

5. 浏览器发送请求信息。

6. 服务器生成响应数据，发送给网络进程，网络进程解析响应内容。

   1. 重定向。返回状态码是 301 或 302，需要重定向到其他 URL，根据`Location`字段获取重定向地址，重新发起新的 HTTP/HTTPS 请求。

   2. 服务器根据`If-None-Match`字段值，返回 304，浏览器的缓存可以使用，从缓存中取资源。

   3. 返回 200，处理响应数据类型。根据

      ```
      Content-Type
      ```

      值，确定响应体的数据类型。

      1. 字段值是`text/html`说明返回数据是 HTML 格式。
      2. `application/octet-stream`说明是字节流类型，浏览器按下载类型处理请求。
      3. 如果是下载类型，URL 导航流程结束。如果是 HTML，会继续接下来的流程。

7. TCP 断开连接。

   1. 如果响应头或请求头有`Connection:keep-alive`字段，不会断开连接。

8. 准备渲染流程。

   1. 一般情况下，每个页面会有单独的渲染进程。
   2. 当多个页面属于同一站点（同根域名和协议相同）时，只会有一个渲染进程，新页面会复用老页面的渲染进程。

9. 准备流程结束后，浏览器进程将 HTML 数据提交给渲染进程。

10. 渲染进程解析页面和子资源，将页面显示出来。

   1. HTML 解析器解析出 DOM 树。
   2. CSS 解释器解析出 CSSOM 树。
   3. 结合两个树得到 render tree，通过 Layout 计算每个元素的宽高颜色位置，绘制元素。





1. 对URL进行解析，确定Web服务器和文件名，生成HTTP请求消息
2. 查询服务器域名对应的IP地址：DNS服务器
3. 传输层 TCP：三次握手
4. 网络层 IP  ：远程定位
5. 两点传输 MAC：在 MAC 包头里需要**发送方 MAC 地址**和**接收方目标 MAC 地址**，
   1. 一般在 TCP/IP 通信里，MAC 包头的**协议类型**只使用：
      - `0800` ： IP 协议
      - `0806` ： ARP 协议
6. 将**数字信息转换为电信号**，才能在网线上传输：网卡
7. 交换机、路由器

## 2. TCP 三次握手，四次握手的过程

**三次握手：**

<img src="04-面试-网络.assets/TCP三次握手.drawio.png" alt="TCP 三次握手" style="zoom: 33%;" />

- 一开始，客户端和服务端都处于 `CLOSE` 状态。先是服务端主动监听某个端口，处于 `LISTEN` 状态
- 客户端会随机初始化序号（`client_isn`），将此序号置于 TCP 首部的「序号」字段中，同时把 `SYN` 标志位置为 `1`，表示 `SYN` 报文。接着把第一个 SYN 报文发送给服务端，表示向服务端发起连接，该报文不包含应用层数据，之后客户端处于 `SYN-SENT` 状态。
- 服务端收到客户端的 `SYN` 报文后，首先服务端也随机初始化自己的序号（`server_isn`），将此序号填入 TCP 首部的「序号」字段中，其次把 TCP 首部的「确认应答号」字段填入 `client_isn + 1`, 接着把 `SYN` 和 `ACK` 标志位置为 `1`。最后把该报文发给客户端，该报文也不包含应用层数据，之后服务端处于 `SYN-RCVD` 状态。
- 客户端收到服务端报文后，还要向服务端回应最后一个应答报文，首先该应答报文 TCP 首部 `ACK` 标志位置为 `1` ，其次「确认应答号」字段填入 `server_isn + 1` ，最后把报文发送给服务端，这次报文可以携带客户到服务端的数据，之后客户端处于 `ESTABLISHED` 状态。
- 服务端收到客户端的应答报文后，也进入 `ESTABLISHED` 状态。

从上面的过程可以发现**第三次握手是可以携带数据的，前两次握手是不可以携带数据的**，这也是面试常问的题。

**四次挥手**

<img src="04-面试-网络.assets/format,png-20230309230614791.png" alt="客户端主动关闭连接 —— TCP 四次挥手" style="zoom:40%;" />

- 客户端打算关闭连接，此时会发送一个 TCP 首部 `FIN` 标志位被置为 `1` 的报文，也即 `FIN` 报文，之后客户端进入 `FIN_WAIT_1` 状态。
- 服务端收到该报文后，就向客户端发送 `ACK` 应答报文，接着服务端进入 `CLOSE_WAIT` 状态。
- 客户端收到服务端的 `ACK` 应答报文后，之后进入 `FIN_WAIT_2` 状态。
- 等待服务端处理完数据后，也向客户端发送 `FIN` 报文，之后服务端进入 `LAST_ACK` 状态。
- 客户端收到服务端的 `FIN` 报文后，回一个 `ACK` 应答报文，之后进入 **`TIME_WAIT` 状态**
- 服务端收到了 `ACK` 应答报文后，就进入了 `CLOSE` 状态，至此服务端已经完成连接的关闭。
- 客户端在经过 `2MSL` 一段时间后，自动进入 `CLOSE` 状态，至此客户端也完成连接的关闭。

你可以看到，每个方向都需要**一个 FIN 和一个 ACK**，因此通常被称为**四次挥手**。

这里一点需要注意是：**主动关闭连接的，才有 TIME_WAIT 状态。**



## 3. 为什么是三次握手？不是两次？四次？

https://xiaolincoding.com/network/3_tcp/tcp_interview.html#%E4%B8%BA%E4%BB%80%E4%B9%88%E6%98%AF%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B-%E4%B8%8D%E6%98%AF%E4%B8%A4%E6%AC%A1%E3%80%81%E5%9B%9B%E6%AC%A1

- （主要原因）**TCP 使用三次握手建立连接的最主要原因是防止「历史连接」初始化了连接。**
- 三次握手才可以同步双方的初始序列号
- 三次握手才可以避免资源浪费

<img src="04-面试-网络.assets/format,png-20230309230525514.png" alt="三次握手避免历史连接" style="zoom:40%;" />

TCP 建立连接时，通过三次握手**能防止历史连接的建立，能减少双方不必要的资源开销，能帮助双方同步初始化序列号**。序列号能够保证数据包不重复、不丢弃和按序传输。

不使用「两次握手」和「四次握手」的原因：

- 「两次握手」：无法防止历史连接的建立，会造成双方资源的浪费，也无法可靠的同步双方序列号；
- 「四次握手」：三次握手就已经理论上最少可靠连接建立，所以不需要使用更多的通信次数。

## 4. 为什么挥手四次？

- 关闭连接时，客户端向服务端发送 `FIN` 时，仅仅表示客户端不再发送数据了但是还能接收数据。
- 服务端收到客户端的 `FIN` 报文时，先回一个 `ACK` 应答报文，而服务端可能还有数据需要处理和发送，等服务端不再发送数据时，才发送 `FIN` 报文给客户端来表示同意现在关闭连接。

从上面过程可知，服务端通常需要等待完成数据的发送和处理，所以服务端的 `ACK` 和 `FIN` 一般都会分开发送，因此是需要四次挥手。

但是**在特定情况下，四次挥手是可以变成三次挥手的**







## 5.  TIME_WAIT出现在什么时候？要等到多久？2MSL为什么要等这么久？

客户端（主动断开连接方）在收到第三次挥手后，会进入TIme_WAIT状态，开启时长为2MSL的定时器，如果中途再次收到第三次挥手的报文后，就会重置定时器，当等待2MSL时长后，客户端就会断开连接。

`MSL` 是 Maximum Segment Lifetime，**报文最大生存时间**，它是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃。因为 TCP 报文基于是 IP 协议的，而 IP 头中有一个 `TTL` 字段，是 IP 数据报可以经过的最大路由数，每经过一个处理他的路由器此值就减 1，当此值为 0 则数据报将被丢弃，同时发送 ICMP 报文通知源主机。

MSL 与 TTL 的区别： MSL 的单位是时间，而 TTL 是经过路由跳数。所以 **MSL 应该要大于等于 TTL 消耗为 0 的时间**，以确保报文已被自然消亡。

**TTL 的值一般是 64，Linux 将 MSL 设置为 30 秒，意味着 Linux 认为数据报文经过 64 个路由器的时间不会超过 30 秒，如果超过了，就认为报文已经消失在网络中了**。

TIME_WAIT 等待 2 倍的 MSL，比较合理的解释是： **网络中可能存在来自发送方的数据包，当这些发送方的数据包被接收方处理后又会向对方发送响应，所以一来一回需要等待 2 倍的时间**。

比如，如果被动关闭方没有收到断开连接的最后的 ACK 报文，就会触发超时重发 `FIN` 报文，另一方接收到 FIN 后，会重发 ACK 给被动关闭方， 一来一去正好 2 个 MSL。

可以看到 **2MSL时长** 这其实是相当于**至少允许报文丢失一次**。比如，若 ACK 在一个 MSL 内丢失，这样被动方重发的 FIN 会在第 2 个 MSL 内到达，TIME_WAIT 状态的连接可以应对。

为什么不是 4 或者 8 MSL 的时长呢？你可以想象一个丢包率达到百分之一的糟糕网络，连续两次丢包的概率只有万分之一，这个概率实在是太小了，忽略它比解决它更具性价比。

`2MSL` 的时间是从**客户端接收到 FIN 后发送 ACK 开始计时的**。如果在 TIME-WAIT 时间内，因为客户端的 ACK 没有传输到服务端，客户端又接收到了服务端重发的 FIN 报文，那么 **2MSL 时间将重新计时**。

在 Linux 系统里 `2MSL` 默认是 `60` 秒，那么一个 `MSL` 也就是 `30` 秒。**Linux 系统停留在 TIME_WAIT 的时间为固定的 60 秒**。



**为什么需要TIME_WAIT状态？**

1. 为了防止历史连接中的数据，被后面相同四元组的连接错误的接收，因此 TCP 设计了 TIME_WAIT 状态，状态会持续 `2MSL` 时长，这个时间**足以让两个方向上的数据包都被丢弃，使得原来连接的数据包在网络中都自然消失，再出现的数据包一定都是新建立连接所产生的。**
2. 保证 「被动关闭连接」的一方，能被正确的关闭，也就是说，TIME-WAIT 作用是**等待足够的时间以确保最后的 ACK 能让被动关闭方接收，从而帮助其正常关闭。**



**如果服务端要避免过多的 TIME_WAIT 状态的连接，就永远不要主动断开连接，让客户端去断开，由分布在各处的客户端去承受 TIME_WAIT**。

**什么场景下服务端会主动断开连接呢？**主动断开连接就会产生TIME_WAIT

- 第一个场景：HTTP 没有使用长连接
- 第二个场景：HTTP 长连接超时
- 第三个场景：HTTP 长连接的请求数量达到上限



## 6. 如果已经建立了连接，但是客户端突然出现故障了怎么办？



TCP 有**保活机制**。这个机制的原理是这样的：

定义一个时间段，在这个时间段内，如果没有任何连接相关的活动，TCP 保活机制会开始作用，每隔一个时间间隔，发送一个探测报文，该探测报文包含的数据非常少，如果连续几个探测报文都没有得到响应，则认为当前的 TCP 连接已经死亡，系统内核将错误信息通知给上层应用程序。

如果开启了 TCP 保活，需要考虑以下几种情况：

- 第一种，对端程序是正常工作的。当 TCP 保活的探测报文发送给对端, 对端会正常响应，这样 **TCP 保活时间会被重置**，等待下一个 TCP 保活时间的到来。
- 第二种，对端主机宕机并重启。当 TCP 保活的探测报文发送给对端后，对端是可以响应的，但由于没有该连接的有效信息，**会产生一个 RST 报文**，这样很快就会发现 TCP 连接已经被重置。
- 第三种，是对端主机宕机（*注意不是进程崩溃，进程崩溃后操作系统在回收进程资源的时候，会发送 FIN 报文，而主机宕机则是无法感知的，所以需要 TCP 保活机制来探测对方是不是发生了主机宕机*），或对端由于其他原因导致报文不可达。当 TCP 保活的探测报文发送给对端后，石沉大海，没有响应，连续几次，达到保活探测次数后，**TCP 会报告该 TCP 连接已经死亡**。

TCP 保活的这个机制检测的时间是有点长，我们可以自己在应用层实现一个心跳机制。

比如，web 服务软件一般都会提供 `keepalive_timeout` 参数，用来指定 HTTP 长连接的超时时间。如果设置了 HTTP 长连接的超时时间是 60 秒，web 服务软件就会**启动一个定时器**，如果客户端在完成一个 HTTP 请求后，在 60 秒内都没有再发起新的请求，**定时器的时间一到，就会触发回调函数来释放该连接。**

为了避免资源浪费，web服务软件一般都可以指定HTTP长连接的超时时间，假设设置了 HTTP 长连接的超时时间是 60 秒，nginx 就会启动一个「定时器」，**如果客户端在完后一个 HTTP 请求后，在 60 秒内都没有再发起新的请求，定时器的时间一到，nginx 就会触发回调函数来关闭该连接，那么此时服务端上就会出现 TIME_WAIT 状态的连接**。

## 7 如果已经建立了连接，但是服务端的进程崩溃会发生什么？

TCP 的连接信息是由内核维护的，所以当服务端的进程崩溃后，内核需要回收该进程的所有 TCP 连接资源，于是内核会发送第一次挥手 FIN 报文，后续的挥手过程也都是在内核完成，并不需要进程的参与，所以即使服务端的进程退出了，还是能与客户端完成 TCP 四次挥手的过程。

## 8 TCP 如何保证它的数据的顺序性


TCP（传输控制协议）通过序号（Sequence Number）和确认序号（Acknowledgment Number）来保证数据的顺序性。以下是TCP如何实现数据顺序性的主要机制：

1. **序号（Sequence Number）：** 每个TCP报文段都有一个序号字段，用来标识报文段中第一个字节的序号。发送方会对每个发送的字节进行编号，接收方使用这个序号来按正确的顺序组装数据。TCP使用32位的序号字段，因此序号可以达到很大的范围。
2. **确认序号（Acknowledgment Number）：** 在TCP通信中，接收方向发送方确认已成功接收的数据，同时通过确认序号告诉发送方下一次期望接收的数据的序号。这有助于发送方知道哪些数据已经成功到达，哪些数据还需要重传。
3. **滑动窗口机制：** TCP使用滑动窗口来控制流量和确保顺序性。发送方维护一个发送窗口，表示可以发送的字节范围，而接收方维护一个接收窗口，表示可以接收的字节范围。滑动窗口机制允许发送方在不等待确认的情况下继续发送数据，从而提高效率。
4. **流控制：** TCP使用流控制机制来防止发送方发送过多的数据，以避免超过接收方的处理能力。通过控制窗口大小，TCP可以确保在网络中的合理流量控制下进行数据传输，从而保持顺序性。



## 9 TCP重传机制

- **超时重传**

TCP 的策略是**超时间隔加倍** ， 就是 每当遇到一次超时重传的时候，都会将下一次超时时间间隔设为先前值的两倍。两次超时，就说明网络环境差，不宜频繁反复发送。

- **快速重传**

TCP 还有另外一种**快速重传（Fast Retransmit）机制**，它**不以时间为驱动，而是以数据驱动重传**。



## 10 TCP滑动窗口、流量控制

**流量控制是为了控制发送方发送速率，保证接收方来得及接收，TCP利用滑动窗口机制来实现流量控制，接收方根据自己的处理能力，动态调整自己的可接收数据的窗口大小，通过ACK报文将窗口大小告知发送方，发送方根据收到的窗口大小，调整发送数据的流量。**



滑动窗口可以指定窗口大小，窗口大小就是指**无需等待确认应答，而可以继续发送数据的最大值**。

窗口的实现实际上是操作系统开辟的一个缓存空间，发送方主机在等到确认应答返回之前，必须在缓冲区中保留已发送的数据。如果按期收到确认应答，此时数据就可以从缓存区清除。

> 窗口大小由哪一方决定？

TCP 头里有一个字段叫 `Window`，也就是窗口大小。

**这个字段是接收端告诉发送端自己还有多少缓冲区可以接收数据。于是发送端就可以根据这个接收端的处理能力来发送数据，而不会导致接收端处理不过来。**

所以，**通常窗口的大小是由接收方的窗口大小来决定的。**

发送方发送的数据大小不能超过接收方的窗口大小，否则接收方就无法正常接收到数据。



## 11 TCP拥塞控制

**在网络出现拥堵时，如果继续发送大量数据包，可能会导致数据包丢失或者时延增大等，这时 TCP 就会重传数据，但是一重传就会导致网络的负担更重，于是会导致更大的延迟以及更多的丢包，这个情况就会进入恶性循环被不断地放大....**

**TCP的拥塞控制机制可以根据网络链路的实时状态 自动调整发送速度，降低发送的数据量，从而避免发送方的数据填满整个网络。**

**TCP根据拥塞窗口来控制发送速度，拥塞窗口 跟接收窗口类似，同样规定了发送方此刻能够发送出去的字节数，只不过他是通过评估网络链路的拥塞程度，并由一定的算法计算而来的，发送方的发送窗口大小由接收窗口和拥塞窗口共同决定，取拥塞窗口和接收窗口中的最小值。**

**TCP通过慢启动、拥塞避免、拥塞发生、快速恢复四种算法来进行拥塞控制**



所以，TCP 不能忽略网络上发生的事，它被设计成一个无私的协议，当网络发送拥塞时，TCP 会自我牺牲，降低发送的数据量。

于是，就有了**拥塞控制**，控制的目的就是**避免「发送方」的数据填满整个网络。**

为了在「发送方」调节所要发送数据的量，定义了一个叫做「**拥塞窗口**」的概念。

> 拥塞控制有哪些控制算法？

拥塞控制主要是四个算法：

1. **慢启动**

TCP 在刚建立连接完成后，首先是有个慢启动的过程，这个慢启动的意思就是一点一点的提高发送数据包的数量，如果一上来就发大量的数据，这不是给网络添堵吗？

慢启动的算法记住一个规则就行：**当发送方每收到一个 ACK，拥塞窗口 cwnd 的大小就会加 1。**

2. **拥塞避免**

当拥塞窗口 `cwnd` 「超过」慢启动门限 `ssthresh` 就会进入拥塞避免算法。

一般来说 `ssthresh` 的大小是 `65535` 字节。

那么进入拥塞避免算法后，它的规则是：**每当收到一个 ACK 时，cwnd 增加 1/cwnd。**

3. **拥塞发生**

当网络出现拥塞，也就是会发生数据包重传，重传机制主要有两种：

- 超时重传
- 快速重传

这两种使用的拥塞发送算法是不同的，接下来分别来说说。

> 发生超时重传的拥塞发生算法

当发生了「超时重传」，则就会使用拥塞发生算法。

这个时候，ssthresh 和 cwnd 的值会发生变化：

- `ssthresh` 设为 `cwnd/2`，
- `cwnd` 重置为 `1` （是恢复为 cwnd 初始化值，我这里假定 cwnd 初始化值 1）

> 发生快速重传的拥塞发生算法

还有更好的方式，前面我们讲过「快速重传算法」。当接收方发现丢了一个中间包的时候，发送三次前一个包的 ACK，于是发送端就会快速地重传，不必等待超时再重传。

TCP 认为这种情况不严重，因为大部分没丢，只丢了一小部分，则 `ssthresh` 和 `cwnd` 变化如下：

- `cwnd = cwnd/2` ，也就是设置为原来的一半;
- `ssthresh = cwnd`;
- 进入快速恢复算法

4. **快速恢复**

快速重传和快速恢复算法一般同时使用，快速恢复算法是认为，你还能收到 3 个重复 ACK 说明网络也不那么糟糕，所以没有必要像 `RTO` 超时那么强烈。



## 12. 假设有两台服务器，怎么确定这两台服务器是否网络可通（不能用ping）

- **telnet命令：** 使用`telnet`检查服务器之间的特定端口是否开放。
- **nc（netcat）命令：** 用于在两个服务器之间建立连接，测试网络通信。
- **curl或wget命令：** 使用HTTP或其他协议测试网络可达性。
- **nmap命令：** 用于扫描目标服务器的开放端口。

> 那假设A服务器开了8080端口，B服务器用什么命令去访问

如果服务器A开放了8080端口，你可以使用`telnet`、`nc`（netcat）、`curl`或`wget`等命令来测试服务器B是否能够访问服务器A的8080端口。以下是一些示例：

## 13. Http和 grpc 的关系

1. **编解码层：**

Http1.1中序列化协议使用JSON进行明文传输，额外开销大，没有类型，开发时需要通过反射同一解决

<img src="04-面试-网络.assets/image-20240326211343158.png" alt="image-20240326211343158" style="zoom:70%;" />

RPC：序列化协议：以gRPC为代表的protobuf

​			序列化后的体积比JSON小  => 传输效率高

​			序列化、反序列化的速度快，开发时不需要反射  ==> 性能消耗低

​			IDL描述语义比较清晰

<img src="04-面试-网络.assets/image-20240326211403550.png" alt="image-20240326211403550" style="zoom:50%;" />

2. **通信协议层**

基于TCP传输，都会有消息头和消息体，区别在于消息头

- HTTP1.1  
  - 优点是灵活，可以自定义很多字段
  - 缺点是包含很多为了适应浏览器的冗余字段，这些字段是内部服务用不到的
- RPC
  - 可定制化，自定义必要的字段即可
  - 可摒弃很多 HTTP Header 中的字段，比如各种浏览器行为

3. **网络传输层**

本质都是基于Socket进行通信

- HTTP1.1
  - 建立一个TCP长连接，设置 keep-alive 长时间复用这个连接
  - 框架中会引入成熟的网络库，给HTTP加连接池，保证不只有一个TCP连接可用
- RPC
  - 建立TCP连接池、框架也会引入成熟的网络库来提高传输性能
  - gRPC基于HTTP2 ， 拥有多路复用、优先级控制、头部压缩等优势





1. **HTTP**:
   - **协议类型**: HTTP是一种基于文本的协议，**使用明文传输**，其语义定义在RFC文档中。
   - **应用场景**: HTTP广泛应用于万维网（World Wide Web）中，是Web应用程序通信的基础。
   - **传输方式**: 基于请求-响应模式，通常使用TCP作为传输层协议，但也可以使用TLS/SSL进行加密。
   - **消息格式**: HTTP消息格式包括请求头、请求体、响应头和响应体，通常使用文本格式，例如JSON、XML等。
   - **异步支持**: HTTP/1.1开始支持持久连接以及分块传输编码，但是异步支持较差。
   - **典型应用**: 用于Web页面的传输、RESTful API等。
2. **gRPC**:
   - **协议类型**: gRPC是基于HTTP/2的远程过程调用（RPC）框架，其定义了一种标准的RPC协议**，使用二进制格式进行通信。**
   - **应用场景**: gRPC通常用于构建分布式系统中的服务间通信，特别适用于微服务架构。
   - **传输方式**: 基于HTTP/2协议，支持双向流（Bidirectional streaming）和多路复用（Multiplexing），可以在单个TCP连接上同时发送多个RPC请求和响应。
   - **消息格式**: 使用Protocol Buffers（ProtoBuf）作为默认的消息序列化格式，ProtoBuf是一种高效的二进制序列化工具。
   - **异步支持**: gRPC天生支持异步通信，可以实现客户端流、服务器流和双向流式RPC。
   - **典型应用**: 适用于构建高性能、跨语言的分布式系统，特别是面向服务的架构。

关系：

- gRPC可以在HTTP/2之上运行，利用了HTTP/2的一些优势，如多路复用、流式传输等。因此，可以说gRPC是HTTP/2的应用之一。
- gRPC与HTTP相比，更适合构建复杂的分布式系统，尤其是需要高性能、跨语言通信的场景。相对而言，HTTP更适用于简单的Web应用场景。
- gRPC和HTTP都是应用层协议，但gRPC提供了更高级别的抽象，使得开发者能够更轻松地实现远程过程调用和异步通信。

 

## 14. RPC的通信流程

桩文件  -->   序列化  --> TCP/UDP

- 定义IDL文件，编译工具生成stub桩文件，相当于生成了静态库，实现函数映射
- 网络里传输的数据都是二进制数据，需要把请求参数、返回结果进行encode和decode
- 根据RPC协议约定  数据头、元数据、消息体等，保证有ID能使请求和返回结果做到一一映射
- 基于成熟的网络库进行TCP/UDP传输

<img src="04-面试-网络.assets/image-20240326205151228.png" alt="image-20240326205151228" style="zoom:50%;" />

总结：

- **函数映射：**静态代理，生成stub桩文件
  - 对比建立HTTP请求连接，RPC在编写代码时，降低了复杂度
  - stub文件让远程调用看起来像是本地调用
- **序列化：**为了生成二进制数据
  - HTTP/1 直接发送 JSON，明文传输
  - gRPC以 protobuf 作为序列化协议
- **网络传输：**
  - 自定义RPC协议实现通信，大厂几乎都用自定义RPC框架去自定义RPC协议
  - 使用成熟的网络库，实现多路复用、可靠传输











